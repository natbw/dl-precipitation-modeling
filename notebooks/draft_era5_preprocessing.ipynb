{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee548a4-4c38-4a4c-8e2c-ee56b152414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d9d7f0-0d39-4013-a8b2-687076cb41b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Zarr file from ../data/era5_subset_1980-01-01_to_2020-12-31.zarr ...\n",
      "Selected features: ['divergence', 'geopotential', 'relative_humidity', 'specific_humidity', 'temperature', 'u_component_of_wind', 'v_component_of_wind', 'vertical_velocity']\n",
      "Target: total_precipitation\n",
      "No missing values found.\n",
      "Unscaled dataframe saved to ..\\data\\era5_standard.csv\n",
      "Train size: (13149, 9)\n",
      "Validation size: (1096, 9)\n",
      "Test size: (731, 9)\n",
      "Preprocessed data saved to ..\\data\\era5_processed.npz\n"
     ]
    }
   ],
   "source": [
    "def era5_preprocessor(\n",
    "    zarr_path,\n",
    "    save_folder,\n",
    "    train_range,\n",
    "    val_range,\n",
    "    test_range,\n",
    "    features=None,\n",
    "    target=\"total_precipitation\"\n",
    "):\n",
    "    # MAKE SURE FOLDER EXISTS\n",
    "    save_folder = Path(save_folder)\n",
    "    save_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # LOAD ZARR FILE\n",
    "    print(f\"Loading Zarr file from {zarr_path} ...\")\n",
    "    ds = xr.open_zarr(zarr_path).load()\n",
    "\n",
    "    # FILTER FEATURES IF SPECIFIED\n",
    "    if features is None:\n",
    "        features = [v for v in ds.data_vars if v != target]\n",
    "\n",
    "    print(f\"Selected features: {features}\")\n",
    "    print(f\"Target: {target}\")\n",
    "\n",
    "    # CONVERT ZARR TO DATAFRAME\n",
    "    df = ds[features + [target]].to_dataframe()\n",
    "    df = df.drop(columns=[col for col in [\"latitude\", \"longitude\"] if col in df.columns])\n",
    "\n",
    "    # CONFIRM NO NULL VALUES\n",
    "    if df.isnull().values.any():\n",
    "        missing_count = df.isnull().sum().sum()\n",
    "        raise ValueError(f\"Dataset contains {missing_count} missing values. Please handle before proceeding.\")\n",
    "    else:\n",
    "        print(\"No missing values found.\")\n",
    "\n",
    "    # REORDER COLUMNS AND SET DATE TO INDEX\n",
    "    cols = [c for c in df.columns if c != target] + [target]\n",
    "    df = df[cols]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # SAVE UNSCALED TO CSV\n",
    "    df_to_save = df.copy()\n",
    "    df_to_save.index = df_to_save.index.strftime(\"%m-%d-%Y\")\n",
    "    df_to_save.to_csv(save_folder / \"era5_standard.csv\")\n",
    "    print(f\"Unscaled dataframe saved to {save_folder / 'era5_standard.csv'}\")\n",
    "\n",
    "    # SCALE FEATURES\n",
    "    scaler = StandardScaler()\n",
    "    feature_values = df[features].values\n",
    "    scaled_features = scaler.fit_transform(feature_values)\n",
    "    df_scaled = pd.DataFrame(scaled_features, columns=features, index=df.index)\n",
    "    df_scaled[target] = df[target].values\n",
    "\n",
    "    # SPLIT DATA\n",
    "    train_mask = (df_scaled.index >= pd.to_datetime(train_range[0])) & (df_scaled.index <= pd.to_datetime(train_range[1]))\n",
    "    val_mask = (df_scaled.index >= pd.to_datetime(val_range[0])) & (df_scaled.index <= pd.to_datetime(val_range[1]))\n",
    "    test_mask = (df_scaled.index >= pd.to_datetime(test_range[0])) & (df_scaled.index <= pd.to_datetime(test_range[1]))\n",
    "\n",
    "    df_train = df_scaled.loc[train_mask]\n",
    "    df_val = df_scaled.loc[val_mask]\n",
    "    df_test = df_scaled.loc[test_mask]\n",
    "\n",
    "    dates_train = df_train.index.strftime(\"%m-%d-%Y\").to_numpy()\n",
    "    dates_val = df_val.index.strftime(\"%m-%d-%Y\").to_numpy()\n",
    "    dates_test = df_test.index.strftime(\"%m-%d-%Y\").to_numpy()\n",
    "\n",
    "    print(f\"Train size: {df_train.shape}\")\n",
    "    print(f\"Validation size: {df_val.shape}\")\n",
    "    print(f\"Test size: {df_test.shape}\")\n",
    "\n",
    "    # SAVE AS ARRAYS\n",
    "    np.savez(\n",
    "        save_folder / \"era5_processed.npz\",\n",
    "        X_train=df_train[features].values,\n",
    "        y_train=df_train[target].values,\n",
    "        dates_train=dates_train,\n",
    "        X_val=df_val[features].values,\n",
    "        y_val=df_val[target].values,\n",
    "        dates_val=dates_val,\n",
    "        X_test=df_test[features].values,\n",
    "        y_test=df_test[target].values,\n",
    "        dates_test=dates_test,\n",
    "        feature_names=np.array(features),\n",
    "        target_name=target\n",
    "    )\n",
    "\n",
    "    print(f\"Preprocessed data saved to {save_folder / 'era5_processed.npz'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    zarr_path = \"../data/era5_subset_1980-01-01_to_2020-12-31.zarr\"\n",
    "    save_folder = \"../data\"\n",
    "\n",
    "    train_range = (\"1980-01-01\", \"2015-12-31\")\n",
    "    val_range = (\"2016-01-01\", \"2018-12-31\")\n",
    "    test_range = (\"2019-01-01\", \"2020-12-31\")\n",
    "\n",
    "    features = None\n",
    "    target = \"total_precipitation\"\n",
    "    \n",
    "era5_preprocessor(\n",
    "        zarr_path=zarr_path,\n",
    "        save_folder=save_folder,\n",
    "        train_range=train_range,\n",
    "        val_range=val_range,\n",
    "        test_range=test_range,\n",
    "        features=features,\n",
    "        target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89215c50-3495-473f-9ec8-9b5f5fc9aed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
